Metadata-Version: 2.3
Name: faststream
Version: 0.5.18
Summary: FastStream: the simplest way to work with a messaging queues
Project-URL: Homepage, https://faststream.airt.ai/latest/
Project-URL: Documentation, https://faststream.airt.ai/latest/getting-started/
Project-URL: Tracker, https://github.com/airtai/FastStream/issues
Project-URL: Source, https://github.com/airtai/FastStream
Project-URL: Discord, https://discord.gg/qFm6aSqq59
Author-email: airt <info@airt.ai>, Nikita Pastukhov <nikita@pastukhov-dev.ru>
License-File: LICENSE
Keywords: framework,kafka,message brokers,nats,rabbitmq,redis
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: Web Environment
Classifier: Framework :: AsyncIO
Classifier: Framework :: Pydantic
Classifier: Framework :: Pydantic :: 1
Classifier: Framework :: Pydantic :: 2
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: System Administrators
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: System :: Distributed Computing
Classifier: Topic :: System :: Networking
Classifier: Typing :: Typed
Requires-Python: >=3.8
Requires-Dist: anyio<5,>=3.7.1
Requires-Dist: fast-depends<2.5.0,>=2.4.0b0
Requires-Dist: typer!=0.12,<1,>=0.9
Requires-Dist: typing-extensions>=4.8.0
Provides-Extra: confluent
Requires-Dist: confluent-kafka<3,>=2; extra == 'confluent'
Provides-Extra: dev
Requires-Dist: aio-pika<10,>=9; extra == 'dev'
Requires-Dist: aiokafka<0.12,>=0.9; extra == 'dev'
Requires-Dist: bandit==1.7.9; extra == 'dev'
Requires-Dist: cairosvg; extra == 'dev'
Requires-Dist: codespell==2.3.0; extra == 'dev'
Requires-Dist: confluent-kafka-stubs; (python_version >= '3.11') and extra == 'dev'
Requires-Dist: confluent-kafka<3,>=2; extra == 'dev'
Requires-Dist: coverage[toml]==7.6.1; extra == 'dev'
Requires-Dist: detect-secrets==1.5.0; extra == 'dev'
Requires-Dist: dirty-equals==0.7.1.post0; extra == 'dev'
Requires-Dist: email-validator==2.2.0; extra == 'dev'
Requires-Dist: fastapi==0.112.0; extra == 'dev'
Requires-Dist: griffe-typingdoc==0.2.5; extra == 'dev'
Requires-Dist: httpx==0.27.0; extra == 'dev'
Requires-Dist: mdx-include==1.4.2; extra == 'dev'
Requires-Dist: mike==2.1.2; extra == 'dev'
Requires-Dist: mkdocs-git-revision-date-localized-plugin==1.2.6; extra == 'dev'
Requires-Dist: mkdocs-glightbox==0.4.0; extra == 'dev'
Requires-Dist: mkdocs-literate-nav==0.6.1; extra == 'dev'
Requires-Dist: mkdocs-macros-plugin==1.0.5; extra == 'dev'
Requires-Dist: mkdocs-material==9.5.31; extra == 'dev'
Requires-Dist: mkdocs-minify-plugin==0.8.0; extra == 'dev'
Requires-Dist: mkdocs-static-i18n==1.2.3; extra == 'dev'
Requires-Dist: mkdocstrings[python]==0.25.2; extra == 'dev'
Requires-Dist: mypy==1.11.1; extra == 'dev'
Requires-Dist: nats-py<=3.0.0,>=2.7.0; extra == 'dev'
Requires-Dist: opentelemetry-sdk<2.0.0,>=1.24.0; extra == 'dev'
Requires-Dist: pillow; extra == 'dev'
Requires-Dist: pre-commit==3.5.0; (python_version < '3.9') and extra == 'dev'
Requires-Dist: pre-commit==3.8.0; (python_version >= '3.9') and extra == 'dev'
Requires-Dist: pydantic-settings<3.0.0,>=2.0.0; extra == 'dev'
Requires-Dist: pytest-asyncio==0.23.8; extra == 'dev'
Requires-Dist: pytest==8.3.2; extra == 'dev'
Requires-Dist: pyyaml==6.0.2; extra == 'dev'
Requires-Dist: redis<6.0.0,>=5.0.0; extra == 'dev'
Requires-Dist: requests; extra == 'dev'
Requires-Dist: ruff==0.5.7; extra == 'dev'
Requires-Dist: semgrep==1.84.1; extra == 'dev'
Requires-Dist: types-deprecated; extra == 'dev'
Requires-Dist: types-docutils; extra == 'dev'
Requires-Dist: types-pygments; extra == 'dev'
Requires-Dist: types-pyyaml; extra == 'dev'
Requires-Dist: types-redis; extra == 'dev'
Requires-Dist: types-setuptools; extra == 'dev'
Requires-Dist: types-ujson; extra == 'dev'
Requires-Dist: typing-extensions<4.12.1,>=4.8.0; (python_version < '3.9') and extra == 'dev'
Requires-Dist: watchfiles==0.23.0; extra == 'dev'
Provides-Extra: devdocs
Requires-Dist: cairosvg; extra == 'devdocs'
Requires-Dist: griffe-typingdoc==0.2.5; extra == 'devdocs'
Requires-Dist: mdx-include==1.4.2; extra == 'devdocs'
Requires-Dist: mike==2.1.2; extra == 'devdocs'
Requires-Dist: mkdocs-git-revision-date-localized-plugin==1.2.6; extra == 'devdocs'
Requires-Dist: mkdocs-glightbox==0.4.0; extra == 'devdocs'
Requires-Dist: mkdocs-literate-nav==0.6.1; extra == 'devdocs'
Requires-Dist: mkdocs-macros-plugin==1.0.5; extra == 'devdocs'
Requires-Dist: mkdocs-material==9.5.31; extra == 'devdocs'
Requires-Dist: mkdocs-minify-plugin==0.8.0; extra == 'devdocs'
Requires-Dist: mkdocs-static-i18n==1.2.3; extra == 'devdocs'
Requires-Dist: mkdocstrings[python]==0.25.2; extra == 'devdocs'
Requires-Dist: pillow; extra == 'devdocs'
Requires-Dist: requests; extra == 'devdocs'
Provides-Extra: kafka
Requires-Dist: aiokafka<0.12,>=0.9; extra == 'kafka'
Provides-Extra: lint
Requires-Dist: aio-pika<10,>=9; extra == 'lint'
Requires-Dist: aiokafka<0.12,>=0.9; extra == 'lint'
Requires-Dist: bandit==1.7.9; extra == 'lint'
Requires-Dist: codespell==2.3.0; extra == 'lint'
Requires-Dist: confluent-kafka-stubs; (python_version >= '3.11') and extra == 'lint'
Requires-Dist: confluent-kafka<3,>=2; extra == 'lint'
Requires-Dist: mypy==1.11.1; extra == 'lint'
Requires-Dist: nats-py<=3.0.0,>=2.7.0; extra == 'lint'
Requires-Dist: opentelemetry-sdk<2.0.0,>=1.24.0; extra == 'lint'
Requires-Dist: redis<6.0.0,>=5.0.0; extra == 'lint'
Requires-Dist: ruff==0.5.7; extra == 'lint'
Requires-Dist: semgrep==1.84.1; extra == 'lint'
Requires-Dist: types-deprecated; extra == 'lint'
Requires-Dist: types-docutils; extra == 'lint'
Requires-Dist: types-pygments; extra == 'lint'
Requires-Dist: types-pyyaml; extra == 'lint'
Requires-Dist: types-redis; extra == 'lint'
Requires-Dist: types-setuptools; extra == 'lint'
Requires-Dist: types-ujson; extra == 'lint'
Provides-Extra: nats
Requires-Dist: nats-py<=3.0.0,>=2.7.0; extra == 'nats'
Provides-Extra: optionals
Requires-Dist: aio-pika<10,>=9; extra == 'optionals'
Requires-Dist: aiokafka<0.12,>=0.9; extra == 'optionals'
Requires-Dist: confluent-kafka<3,>=2; extra == 'optionals'
Requires-Dist: nats-py<=3.0.0,>=2.7.0; extra == 'optionals'
Requires-Dist: opentelemetry-sdk<2.0.0,>=1.24.0; extra == 'optionals'
Requires-Dist: redis<6.0.0,>=5.0.0; extra == 'optionals'
Provides-Extra: otel
Requires-Dist: opentelemetry-sdk<2.0.0,>=1.24.0; extra == 'otel'
Provides-Extra: rabbit
Requires-Dist: aio-pika<10,>=9; extra == 'rabbit'
Provides-Extra: redis
Requires-Dist: redis<6.0.0,>=5.0.0; extra == 'redis'
Provides-Extra: test-core
Requires-Dist: coverage[toml]==7.6.1; extra == 'test-core'
Requires-Dist: dirty-equals==0.7.1.post0; extra == 'test-core'
Requires-Dist: pytest-asyncio==0.23.8; extra == 'test-core'
Requires-Dist: pytest==8.3.2; extra == 'test-core'
Requires-Dist: typing-extensions<4.12.1,>=4.8.0; (python_version < '3.9') and extra == 'test-core'
Provides-Extra: testing
Requires-Dist: coverage[toml]==7.6.1; extra == 'testing'
Requires-Dist: dirty-equals==0.7.1.post0; extra == 'testing'
Requires-Dist: email-validator==2.2.0; extra == 'testing'
Requires-Dist: fastapi==0.112.0; extra == 'testing'
Requires-Dist: httpx==0.27.0; extra == 'testing'
Requires-Dist: pydantic-settings<3.0.0,>=2.0.0; extra == 'testing'
Requires-Dist: pytest-asyncio==0.23.8; extra == 'testing'
Requires-Dist: pytest==8.3.2; extra == 'testing'
Requires-Dist: pyyaml==6.0.2; extra == 'testing'
Requires-Dist: typing-extensions<4.12.1,>=4.8.0; (python_version < '3.9') and extra == 'testing'
Requires-Dist: watchfiles==0.23.0; extra == 'testing'
Provides-Extra: types
Requires-Dist: aio-pika<10,>=9; extra == 'types'
Requires-Dist: aiokafka<0.12,>=0.9; extra == 'types'
Requires-Dist: confluent-kafka-stubs; (python_version >= '3.11') and extra == 'types'
Requires-Dist: confluent-kafka<3,>=2; extra == 'types'
Requires-Dist: mypy==1.11.1; extra == 'types'
Requires-Dist: nats-py<=3.0.0,>=2.7.0; extra == 'types'
Requires-Dist: opentelemetry-sdk<2.0.0,>=1.24.0; extra == 'types'
Requires-Dist: redis<6.0.0,>=5.0.0; extra == 'types'
Requires-Dist: types-deprecated; extra == 'types'
Requires-Dist: types-docutils; extra == 'types'
Requires-Dist: types-pygments; extra == 'types'
Requires-Dist: types-pyyaml; extra == 'types'
Requires-Dist: types-redis; extra == 'types'
Requires-Dist: types-setuptools; extra == 'types'
Requires-Dist: types-ujson; extra == 'types'
Description-Content-Type: text/markdown

# FastStream

<b>Effortless event stream integration for your services</b>

---

<p align="center">
  <a href="https://github.com/airtai/faststream/actions/workflows/pr_tests.yaml" target="_blank">
    <img src="https://github.com/airtai/faststream/actions/workflows/pr_tests.yaml/badge.svg?branch=main" alt="Test Passing"/>
  </a>

  <a href="https://coverage-badge.samuelcolvin.workers.dev/redirect/airtai/faststream" target="_blank">
      <img src="https://coverage-badge.samuelcolvin.workers.dev/airtai/faststream.svg" alt="Coverage">
  </a>

  <a href="https://www.pepy.tech/projects/faststream" target="_blank">
    <img src="https://static.pepy.tech/personalized-badge/faststream?period=month&units=international_system&left_color=grey&right_color=green&left_text=downloads/month" alt="Downloads"/>
  </a>

  <a href="https://pypi.org/project/faststream" target="_blank">
    <img src="https://img.shields.io/pypi/v/faststream?label=PyPI" alt="Package version">
  </a>

  <a href="https://pypi.org/project/faststream" target="_blank">
    <img src="https://img.shields.io/pypi/pyversions/faststream.svg" alt="Supported Python versions">
  </a>

  <br/>

  <a href="https://github.com/airtai/faststream/actions/workflows/pr_codeql.yml" target="_blank">
    <img src="https://github.com/airtai/faststream/actions/workflows/pr_codeql.yml/badge.svg" alt="CodeQL">
  </a>

  <a href="https://github.com/airtai/faststream/actions/workflows/pr_dependency-review.yaml" target="_blank">
    <img src="https://github.com/airtai/faststream/actions/workflows/pr_dependency-review.yaml/badge.svg" alt="Dependency Review">
  </a>

  <a href="https://github.com/airtai/faststream/blob/main/LICENSE" target="_blank">
    <img src="https://img.shields.io/github/license/airtai/faststream.png" alt="License">
  </a>

  <a href="https://github.com/airtai/faststream/blob/main/CODE_OF_CONDUCT.md" target="_blank">
    <img src="https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg" alt="Code of Conduct">
  </a>

  <a href="https://discord.gg/qFm6aSqq59" target="_blank">
      <img alt="Discord" src="https://img.shields.io/discord/1085457301214855171?logo=discord">
  </a>
</p>

---

## Features

[**FastStream**](https://faststream.airt.ai/latest/) simplifies the process of writing producers and consumers for message queues, handling all the
parsing, networking and documentation generation automatically.

Making streaming microservices has never been easier. Designed with junior developers in mind, **FastStream** simplifies your work while keeping the door open for more advanced use cases. Here's a look at the core features that make **FastStream** a go-to framework for modern, data-centric microservices.

- **Multiple Brokers**: **FastStream** provides a unified API to work across multiple message brokers ([**Kafka**](https://kafka.apache.org/), [**RabbitMQ**](https://www.rabbitmq.com/), [**NATS**](https://nats.io/), [**Redis**](https://redis.io/) support)

- [**Pydantic Validation**](#writing-app-code): Leverage [**Pydantic's**](https://docs.pydantic.dev/) validation capabilities to serialize and validate incoming messages

- [**Automatic Docs**](#project-documentation): Stay ahead with automatic [**AsyncAPI**](https://www.asyncapi.com/) documentation

- **Intuitive**: Full-typed editor support makes your development experience smooth, catching errors before they reach runtime

- [**Powerful Dependency Injection System**](#dependencies): Manage your service dependencies efficiently with **FastStream**'s built-in DI system

- [**Testable**](#testing-the-service): Supports in-memory tests, making your CI/CD pipeline faster and more reliable

- **Extensible**: Use extensions for lifespans, custom serialization and middleware

- [**Integrations**](#any-framework): **FastStream** is fully compatible with any HTTP framework you want ([**FastAPI**](#fastapi-plugin) especially)

- [**Built for Automatic Code Generation**](#code-generator): **FastStream** is optimized for automatic code generation using advanced models like GPT and Llama

That's **FastStream** in a nutshellâ€”easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, **FastStream** has got you covered.

---

**Documentation**: <a href="https://faststream.airt.ai/latest/" target="_blank">https://faststream.airt.ai/latest/</a>

---

## History

**FastStream** is a new package based on the ideas and experiences gained from [**FastKafka**](https://github.com/airtai/fastkafka) and [**Propan**](https://github.com/lancetnik/propan). By joining our forces, we picked up the best from both packages and created a unified way to write services capable of processing streamed data regardless of the underlying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.

---

## Install

**FastStream** works on **Linux**, **macOS**, **Windows** and most **Unix**-style operating systems.
You can install it with `pip` as usual:

```sh
pip install faststream[kafka]
# or
pip install faststream[rabbit]
# or
pip install faststream[nats]
# or
pip install faststream[redis]
```

By default **FastStream** uses **PydanticV2** written in **Rust**, but you can downgrade it manually, if your platform has no **Rust** support - **FastStream** will work correctly with **PydanticV1** as well.

---

## Writing app code

**FastStream** brokers provide convenient function decorators `@broker.subscriber`
and `@broker.publisher` to allow you to delegate the actual process of:

- consuming and producing data to Event queues, and

- decoding and encoding JSON-encoded messages

These decorators make it easy to specify the processing logic for your consumers and producers, allowing you to focus on the core business logic of your application without worrying about the underlying integration.

Also, **FastStream** uses [**Pydantic**](https://docs.pydantic.dev/) to parse input
JSON-encoded data into Python objects, making it easy to work with structured data in your applications, so you can serialize your input messages just using type annotations.

Here is an example Python app using **FastStream** that consumes data from an incoming data stream and outputs the data to another one:

```python
from faststream import FastStream
from faststream.kafka import KafkaBroker
# from faststream.rabbit import RabbitBroker
# from faststream.nats import NatsBroker
# from faststream.redis import RedisBroker

broker = KafkaBroker("localhost:9092")
# broker = RabbitBroker("amqp://guest:guest@localhost:5672/")
# broker = NatsBroker("nats://localhost:4222/")
# broker = RedisBroker("redis://localhost:6379/")

app = FastStream(broker)

@broker.subscriber("in")
@broker.publisher("out")
async def handle_msg(user: str, user_id: int) -> str:
    return f"User: {user_id} - {user} registered"
```

Also, **Pydantic**â€™s [`BaseModel`](https://docs.pydantic.dev/usage/models/) class allows you
to define messages using a declarative syntax, making it easy to specify the fields and types of your messages.

```python
from pydantic import BaseModel, Field, PositiveInt
from faststream import FastStream
from faststream.kafka import KafkaBroker

broker = KafkaBroker("localhost:9092")
app = FastStream(broker)

class User(BaseModel):
    user: str = Field(..., examples=["John"])
    user_id: PositiveInt = Field(..., examples=["1"])

@broker.subscriber("in")
@broker.publisher("out")
async def handle_msg(data: User) -> str:
    return f"User: {data.user} - {data.user_id} registered"
```

---

## Testing the service

The service can be tested using the `TestBroker` context managers, which, by default, puts the Broker into "testing mode".

The Tester will redirect your `subscriber` and `publisher` decorated functions to the InMemory brokers, allowing you to quickly test your app without the need for a running broker and all its dependencies.

Using pytest, the test for our service would look like this:

```python
# Code above omitted ðŸ‘†

import pytest
import pydantic
from faststream.kafka import TestKafkaBroker


@pytest.mark.asyncio
async def test_correct():
    async with TestKafkaBroker(broker) as br:
        await br.publish({
            "user": "John",
            "user_id": 1,
        }, "in")

@pytest.mark.asyncio
async def test_invalid():
    async with TestKafkaBroker(broker) as br:
        with pytest.raises(pydantic.ValidationError):
            await br.publish("wrong message", "in")
```

## Running the application

The application can be started using built-in **FastStream** CLI command.

To run the service, use the **FastStream CLI** command and pass the module (in this case, the file where the app implementation is located) and the app symbol to the command.

``` shell
faststream run basic:app
```

After running the command, you should see the following output:

``` shell
INFO     - FastStream app starting...
INFO     - input_data |            - `HandleMsg` waiting for messages
INFO     - FastStream app started successfully! To exit press CTRL+C
```

Also, **FastStream** provides you with a great hot reload feature to improve your Development Experience

``` shell
faststream run basic:app --reload
```

And multiprocessing horizontal scaling feature as well:

``` shell
faststream run basic:app --workers 3
```

You can learn more about **CLI** features [here](https://faststream.airt.ai/latest/getting-started/cli/)

---

## Project Documentation

**FastStream** automatically generates documentation for your project according to the [**AsyncAPI**](https://www.asyncapi.com/) specification. You can work with both generated artifacts and place a web view of your documentation on resources available to related teams.

The availability of such documentation significantly simplifies the integration of services: you can immediately see what channels and message formats the application works with. And most importantly, it won't cost anything - **FastStream** has already created the docs for you!

![HTML-page](https://github.com/airtai/faststream/blob/main/docs/docs/assets/img/AsyncAPI-basic-html-short.png?raw=true)

---

## Dependencies

**FastStream** (thanks to [**FastDepends**](https://lancetnik.github.io/FastDepends/)) has a dependency management system similar to `pytest fixtures` and `FastAPI Depends` at the same time. Function arguments declare which dependencies you want are needed, and a special decorator delivers them from the global Context object.

```python
from faststream import Depends, Logger

async def base_dep(user_id: int) -> bool:
    return True

@broker.subscriber("in-test")
async def base_handler(user: str,
                       logger: Logger,
                       dep: bool = Depends(base_dep)):
    assert dep is True
    logger.info(user)
```

---

## HTTP Frameworks integrations

### Any Framework

You can use **FastStream** `MQBrokers` without a `FastStream` application.
Just *start* and *stop* them according to your application's lifespan.

```python
from aiohttp import web

from faststream.kafka import KafkaBroker

broker = KafkaBroker("localhost:9092")

@broker.subscriber("test")
async def base_handler(body):
    print(body)

async def start_broker(app):
    await broker.start()

async def stop_broker(app):
    await broker.close()

async def hello(request):
    return web.Response(text="Hello, world")

app = web.Application()
app.add_routes([web.get("/", hello)])
app.on_startup.append(start_broker)
app.on_cleanup.append(stop_broker)

if __name__ == "__main__":
    web.run_app(app)
```

### **FastAPI** Plugin

Also, **FastStream** can be used as part of **FastAPI**.

Just import a **StreamRouter** you need and declare the message handler with the same `@router.subscriber(...)` and `@router.publisher(...)` decorators.

```python
from fastapi import FastAPI
from pydantic import BaseModel

from faststream.kafka.fastapi import KafkaRouter

router = KafkaRouter("localhost:9092")

class Incoming(BaseModel):
    m: dict

@router.subscriber("test")
@router.publisher("response")
async def hello(m: Incoming):
    return {"response": "Hello, world!"}

app = FastAPI(lifespan=router.lifespan_context)
app.include_router(router)
```

More integration features can be found [here](https://faststream.airt.ai/latest/getting-started/integrations/fastapi/)

---

## Code generator

As evident, **FastStream** is an incredibly user-friendly framework. However, we've taken it a step further and made it even more user-friendly! Introducing [faststream-gen](https://faststream-gen.airt.ai), a Python library that harnesses the power of generative AI to effortlessly generate **FastStream** applications. Simply describe your application requirements, and [faststream-gen](https://faststream-gen.airt.ai) will generate a production-grade **FastStream** project that is ready to deploy in no time.

Save application description inside `description.txt`:
```
Create a FastStream application using localhost broker for testing and use the
default port number.

It should consume messages from the 'input_data' topic, where each message is a
JSON encoded object containing a single attribute: 'data'.

While consuming from the topic, increment the value of the data attribute by 1.

Finally, send message to the 'output_data' topic.
```

and run the following command to create a new **FastStream** project:
``` shell
faststream_gen -i description.txt
```

``` shell
âœ¨  Generating a new FastStream application!
 âœ” Application description validated.
 âœ” FastStream app skeleton code generated. Takes around 15 to 45 seconds)...
 âœ” The app and the tests are generated.  around 30 to 90 seconds)...
 âœ” New FastStream project created.
 âœ” Integration tests were successfully completed.
 Tokens used: 10768
 Total Cost (USD): $0.03284
âœ¨  All files were successfully generated!
```

### Tutorial

We also invite you to explore our tutorial, where we will guide you through the process of utilizing the [faststream-gen](https://faststream-gen.airt.ai) Python library to effortlessly create **FastStream** applications:

- [Cryptocurrency analysis with FastStream](https://faststream-gen.airt.ai/Tutorial/Cryptocurrency_Tutorial/)

---

## Stay in touch

Please show your support and stay in touch by:

- giving our [GitHub repository](https://github.com/airtai/faststream/) a star, and

- joining our [Discord server](https://discord.gg/qFm6aSqq59)

Your support helps us to stay in touch with you and encourages us to
continue developing and improving the framework. Thank you for your
support!

---

## Contributors

Thanks to all of these amazing people who made the project better!

<a href="https://github.com/airtai/faststream/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=airtai/faststream"/>
</a>
